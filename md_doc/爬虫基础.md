[TOC]

[教程来源](https://www.bilibili.com/video/BV1Yh411o7Sz?p=14)

## 1.爬虫简介

抓取互联网上的数据，为我所用。

有了大量的数据，就如同有了一个数据银行一样。

下一步做的就是如何将这些爬取的数据，产品化、商业化。

### 1.1.爬虫合法性探究

#### 1.1.1.爬虫究竟是违法还是合法的？

- 在法律中不被禁止
- 具有违法风险
- 区分为善意爬虫和恶意爬虫

#### 1.1.2.爬虫带来的风险

- 爬虫干扰了被访问网站的正常运营
- 爬虫抓取了受到法律保护的特定类型的数据或信息

#### 1.1.3.如何避免进局子喝茶

- 时常优化自己的程序，避免干扰被访问网站的正常运行
- 在使用、传播爬取到的数据时，审查抓取的内容，如果发现了涉及到用户以及商业机密等敏感内容时，需要及时停止爬取或传播。

### 1.2.爬虫初始深入

#### 1.2.1.爬虫在使用场景中的分类

- 通用爬虫
  - 抓取系统的重要组成部分。
  - 抓取的是一整张页面数据。
- 聚焦爬虫
  - 是建立在通用爬虫的基础之上。
  - 抓取的是页面中特定的局部内容。
- 增量式爬虫
  - 检测网站中数据更新的情况。
  - 只会抓取网站中最新更新出来的数据。

#### 1.2.2.爬虫的矛与盾

- 反爬机制
  - 门户网站，可以通过指定相应的策略或者技术手段，防止爬虫程序进行网站数据的爬取。
- 反反爬策略
  - 爬虫程序，可以通过指定相关的策略或者技术手段，破解门户网站中具备的反爬机制，从而可以获取门户网站的和数据。

#### 1.2.3.robots.txt协议

君子协议，规定了网站中哪些数据可以被爬虫爬取，哪些数据不可以被爬取。

http://www.baidu.com/robots.txt

## 2.http&https协议

详细请点击[http&https协议]()

### 2.1.http协议

- 概念：就是服务器和客户端，进行数据交互的一种形式。
- 常用请求头信息：
  - User-Agent：请求头的身份标识。
  - Connection：请求完毕后，是断开连接还是保持连接。
- 常用响应头信息：
  - Content-Type：服务器响应回客户端的数据类型。

### 2.2.https协议

- 概念：安全的超文本传输协议。

## 3.Requests模块



### 3.1.Requests巩固

#### 3.1.1.深入案例介绍



#### 3.1.2.简易网页采集器



#### 3.1.3.百度翻译



#### 3.1.4.豆瓣电影



#### 3.1.5.作业



### 3.2.综合练习

#### 3.2.1.药监总局01



#### 3.2.2.药监总局02



#### 3.2.3.药监总局03-screenflow



#### 3.2.4.药监总局04-screenflow



### 3.3.总结回顾



## 4.数据解析概述

### 4.1.图片数据爬取



### 4.2.正则解析



### 4.3.bs4解析

#### 4.3.1.bs4解析概述



#### 4.3.2.bs4解析具体使用讲解



#### 4.3.3.bs4解析案例实战

### 4.4.xpath解析

#### 4.4.1.xpath解析基础



#### 4.4.2.xpath实战

##### 4.4.2.1.xpath-58二手房



##### 4.4.2.2.xpath-4k图片解析下载



##### 4.4.2.3.xpath-全国城市名称爬取



##### 4.4.2.4.作业



## 5.验证码识别

### 5.1.验证码识别简介



### 5.2.云打码使用流程



### 5.3.古诗文网验证码识别



## 6.模拟登陆

### 6.1.模拟登陆实现流程梳理



### 6.2.人人网模拟登陆



### 6.3.模拟登陆cookie操作



## 7.代理

### 7.1.代理理论讲解



### 7.2.代理在爬虫中的应用



## 8.异步爬虫

### 8.1.异步爬虫概述



### 8.2.异步爬虫-多进程&多线程



### 8.3.异步爬虫-进程池&线程池



### 8.4.异步爬虫-线程池的基本使用



### 8.5.异步爬虫-线程池案例应用



## 9.协程

### 9.1.协程相关概念

#### 9.1.1.异步编程



#### 9.1.2.协程



#### 9.1.3.协程意义



#### 9.1.4.asyncio异步编程

##### 9.1.4.1asyncio事件循环



##### 9.1.4.2.快速上手



##### 9.1.4.3.await关键词



##### 9.1.4.4.task对象



##### 9.1.4.5.future对象



##### 9.1.4.6.concurrent的future对象



##### 9.1.4.7.异步和非异步混合案例



##### 9.1.4.8.异步迭代器



##### 9.1.4.9.异步上下文管理



##### 9.1.4.10.uvloop



##### 9.1.4.11.案例-异步操作redis



##### 9.1.4.12.案例-异步操作mysql



##### 9.1.4.13.FastApi框架异步



##### 9.1.4.14.异步爬虫



##### 9.1.4.15.总结



### 9.2.协程相关操作



### 9.3.多任务异步协程，实现异步爬虫



## 10.aiohttp模块

### 10.1.aiohttp模块引出



### 10.2.aiohttp+多任务异步协程，实现异步爬虫



## 11.selenium

### 11.1.selenium简介



### 11.2.selenium初试



### 11.3.selenium其他自动化操作



### 11.4.iframe处理+动作链



### 11.5.selenium的模拟登陆



### 11.6.无头浏览器+规避检测



### 11.7.超级鹰的基本使用



## 12.scrapy

### 12.1.scrapy框架初始



### 12.2.scrapy环境安装



### 12.3.scrapy基本使用



### 12.4.scrapy数据解析



### 12.5.持久化存储

#### 12.5.1.基于终端指令的持久化存储



#### 12.5.2.基础管道持久化存储



### 12.6.全站数据爬取



### 12.7.五大核心组件

#### 12.7.1.请求传参



#### 12.7.2.scrapy图片爬取



#### 12.7.3.中间件

##### 12.7.3.1.中间件初始



##### 12.7.3.2.中间件-处理请求



#### 12.7.4.案例-网易新闻



#### 12.7.5.crawlspider的全站数据爬取



### 12.8.分布式

#### 12.8.1.分布式概述



#### 12.8.2.分布式搭建



#### 12.8.3.增量式爬虫





